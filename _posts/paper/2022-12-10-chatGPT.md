---
layout:     post
title:      <chatGPT>学习笔记
subtitle:   2022年12月
date:       2022-12-10
author:     franztao
header-img: post-bg-re-vs-ng2.jpg
catalog: true
tags:
    - GPT
    - Generative Pre-Training

---

李宏毅老师新鲜出炉的关于ChatGPT的解读视频，非常推荐：[Chat GPT (可能)是怎麼煉成的 - GPT 社會化的過程 - YouTube](https://www.youtube.com/watch?v=e0aKI2GGZNg&t=540s)

原文链接：[ChatGPT: Optimizing Language Models for Dialogue](https://openai.com/blog/chatgpt/)

## GPT Introduction

[李宏毅老师 GPT3 ppt](http://speech.ee.ntu.edu.tw/~tlkagk/courses/DLHLP20/GPT3%20(v6).pdf)

模型之大，感官认识如下图说明

![](C:\Users\franztao\AppData\Roaming\marktext\images\2022-12-10-21-08-21-image.png)

模型整体架构

![](C:\Users\franztao\AppData\Roaming\marktext\images\2022-12-10-21-13-19-image.png)

## chatGPT  Introduction

### lihongyi讲解主要内容

1. 学习文字接龙

    2.  人类老师引导文字接龙的方向

3. 模仿人类老师的喜好

4. 用增强学习向模拟老师学习

![](C:\Users\franztao\AppData\Roaming\marktext\images\2022-12-10-20-55-56-image.png)

![](C:\Users\franztao\AppData\Roaming\marktext\images\2022-12-10-20-56-19-image.png)

![](C:\Users\franztao\AppData\Roaming\marktext\images\2022-12-10-20-56-36-image.png)

![](C:\Users\franztao\AppData\Roaming\marktext\images\2022-12-10-20-57-10-image.png)

## OpenAI官网内容解读

OpenAI 开放了一个支持交互式对话的 ChatGPT 模型，可以遵循提示中的指令并提供详细的响应：回答问题、承认错误、拒绝不适当的请求等。以下是官方示例：

![](C:\Users\franztao\AppData\Roaming\marktext\images\2022-12-10-20-37-36-image.png)

团队使用了 RLHF（Reinforcement Learning from Human Feedback，来自人类反馈的强化学习）训练模型。

> - 步骤1：人工智能训练师分别扮演用户、AI助手两个角色进行对话，训练初始模型，并确定回答的基本策略。
> 
> - 步骤2：人工智能培训师与聊天机器人进行对话，收集比较数据（包括两个或多个按质量排名的模型响应），创建强化学习的奖励模型。
> 
> - 步骤3：使用近端策略优化（Proximal Policy Optimization）完成对上述模型的微调，并在此过程执行多次迭代。

![](C:\Users\franztao\AppData\Roaming\marktext\images\2022-12-10-20-37-51-image.png)