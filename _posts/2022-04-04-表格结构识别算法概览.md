---
layout:     post
title:      表格结构识别算法概览
subtitle:   2022年3月
date:       2022-4-3
author:     franztao
header-img: post-bg-re-vs-ng2.jpg
catalog: true
tags:
    - Tsr

---

# 简介背景

## 历史由来

From Sumer to Spreadsheets 从古老石块上，人类记录信息的形式就有表格的呈现形式
![sumer](https://raw.githubusercontent.com/franztao/blog_picture/main/2022-04-04-表格结构识别算法概览/sumer.png)
![excel](https://raw.githubusercontent.com/franztao/blog_picture/main/2022-04-04-表格结构识别算法概览/excel.png)

## 价值

> 表格是各类文档中常见的页面元素，随着各类文档的爆炸性增长，如何高效地从文档中找到表格并获取内容与结构信息即表格识别，成为了一个亟需解决的问题。表格识别的难点总结如下：
> 表格作为一种高效的数据组织和展现的方式，是文档页面中最重要的数据对象之一。表格在教育场景中分布广泛，种类繁多。对表格结构的还原和内容的识别，能帮助计算机更好的理解表格，在教学内容生产、智能解答等场景下，具有非常重要的应用价值。随着深度学习技术的飞速发展，目标检测、OCR和文档结构识别等技术也取得了许多新的进展，为表格识别提供了多种可能的解决方案。

### 学术上的价值

> 

### 工业上的价值

在提高生产效率、调整产业结构、提高产品服务质量、降低人工运营成本等战略目标的驱动下，我国各行各业都在从传统模式向数字化、网络化、智能化转变。例如，制造业正在从粗放型向质量效益型转变，从高污染、高能耗向绿色制造转变，从生产型向“生产+服务”型转变，逐步走向智能化，其中，**AI技术大大加快了智能制造的步伐。**

### 公司上的价值

> 跟ocsr一起闭环，成为实验描述提取端到端解决方案，实现商业价值

### 个人上的价值

> 设计cv的文本检测和文本识别，nlp的文本分类，prompt。多模态，vqa技术

# 定义

## 表格数据呈现形式的本质

Meaning in Tables Meaning = Language + Layout
![img_1.png](https://raw.githubusercontent.com/franztao/blog_picture/main/2022-04-04-表格结构识别算法概览/img_1.png)

## 表格数据呈现的语义逻辑

![img_4.png](https://raw.githubusercontent.com/franztao/blog_picture/main/2022-04-04-表格结构识别算法概览/img_4.png)

![](https://raw.githubusercontent.com/franztao/blog_picture/main/marktext/2022-04-06-17-52-49-image.png)

![](https://raw.githubusercontent.com/franztao/blog_picture/main/marktext/2022-04-06-17-53-01-image.png)

![](https://raw.githubusercontent.com/franztao/blog_picture/main/marktext/2022-04-06-17-53-14-image.png)

![](https://raw.githubusercontent.com/franztao/blog_picture/main/marktext/2022-05-18-11-33-32-image.png)

![](C:\Users\franztao\AppData\Roaming\marktext\images\2022-08-30-11-20-29-image.png)

![](C:\Users\franztao\AppData\Roaming\marktext\images\2022-08-30-11-20-57-image.png)

## 表格数据存储格式

![img_5.png](https://raw.githubusercontent.com/franztao/blog_picture/main/2022-04-04-表格结构识别算法概览/img_5.png)

## 表格分类

    存储格式
        pdf
        图片
    展现形式
        垂直
        水平
        旋转X度
    记录方式
        电子记录
        手写
        扫描
    表达形式
        竖表
        横表
        复合表
    表格内容
        单表
        多表
    格子形式
        Lattice : For tables formed with lines.
            border
        Stream : For tables formed with whitespaces.
            borderless
    逻辑结构
        同一列里展示两列数据
        两列上面有共同的主列
    图片质量
        整体：分辨率/清晰度
        局部：噪音程度/类型
    文档类型
    文档来源
    研究领域

# document AI任务描述及相关子任务

表格结构识别是属于document AI任务的子任务，从整体document AI任务看表格结构识别在技术链上的定位

![The three points of view](https://raw.githubusercontent.com/franztao/blog_picture/main/2022-04-04-表格结构识别算法概览/The_three_points_of_view.png)

## 1. Document analysis and understanding

**5tasks**

> 1. Table detection
> 
> 2. Structure Recognition
> 
> 3. Functional Analysis
> 
> 4. Structural Analysis
> 
> 5. Interpretation

![img_2.png](https://raw.githubusercontent.com/franztao/blog_picture/main/2022-04-04-表格结构识别算法概览/img_2.png)

## 2. semantic web + Volume large database

**3 sub -tasks**

> 1. Entity Linking
> 
> 2. Column Type Identification
> 
> 3. Relation Extraction

![img_3.png](https://raw.githubusercontent.com/franztao/blog_picture/main/2022-04-04-表格结构识别算法概览/img_3.png)

## 3. semantic table interpretation

![3 stages of the Table Understanding](https://raw.githubusercontent.com/franztao/blog_picture/main/2022-04-04-表格结构识别算法概览/img_6.png)

> Table Detection: detecting the tabular boundaries in
> terms of bounding boxes in document images.
> 
> Table Structural Segmentation（cell topology recognition）: defines the structure of table by analyzing information of row and column layouts.
> 
> Table Recognition(cell location recognition): includes both structural segmentation and parsing information of table cells.
> 
> ocr(cell content recognition)

![](https://raw.githubusercontent.com/franztao/blog_picture/main/marktext/2022-07-21-23-07-57-image.png)

## 子任务 DOD document object analysis

![](https://raw.githubusercontent.com/franztao/blog_picture/main/marktext/2022-04-22-17-26-19-image.png)

## 

![](C:\Users\franztao\AppData\Roaming\marktext\images\2022-09-01-10-39-32-image.png)

![](C:\Users\franztao\AppData\Roaming\marktext\images\2022-09-01-16-20-39-image.png)

## 子任务 OCR

# 衡量指标 metric

### 格子bbox metric

1. P R Recall

2. [BLEU](https://blog.csdn.net/g11d111/article/details/100103208)

3. map@IOU coco标准

4. GriTS
   
   ![](https://raw.githubusercontent.com/franztao/blog_picture/main/marktext/2022-04-14-14-28-28-image.png)
   
   > ("grits") computes the grid table similarity (GriTS) metrics for table structure recognition. GriTS is a measure of table cell correctness and is defined as the average correctness of each cell averaged over all tables. GriTS can measure the correctness of predicted cells based on: 1. cell topology alone, 2. cell topology and the reported bounding box location of each cell, or 3. cell topology and the reported text content of each cell. For more details on GriTS ![Comparison of metrics proposed for table structure recognition](https://raw.githubusercontent.com/franztao/blog_picture/main/2022-04-04-%E8%A1%A8%E6%A0%BC%E7%BB%93%E6%9E%84%E8%AF%86%E5%88%AB%E7%AE%97%E6%B3%95%E6%A6%82%E8%A7%88/Comparison_of_metrics_proposed_for_table_structure_recognition.png)
   
   5. STIOU
   
   ![1-2.png](https://github.com/Yuliang-Liu/TIoU-metric/blob/master/Readme_sources/1-2.png?raw=true)

5. TEDS

![](C:\Users\franztao\AppData\Roaming\marktext\images\2022-10-24-16-00-14-image.png)

### 文本metric

1. 普通文本
   
   > - one 全对准确率： 每张图片版面上有多个文本时候，每个文本都对的张数占总的张数的比例； 标签全对准确率：每张图片版面上有多个文本时候，文本对的个数占总的文本个数的比例；
   > - 平均编辑距离：平均编辑距离越小说明识别率越高。平均编辑距离主要衡量整行或整篇文章的指标，可以同时反应识别错，漏识别和多识别的情况；
   > - 字符识别准确率，即识别对的字符数占总识别出来字符数的比例，可以反应识别错和多识别的情况，但无法反应漏识别的情况；
   > - 字符识别召回率，即识别对的字符数占实际字符数的比例，可以反应识别错和漏识别的情况，但是没办法反应多识别的情况，可以配套字符识别准确率一起使用；
   > - 文本行定位为的准确率和召回率，同字符识别的准确率和召回率。主要反应文本行定位的指标，是ocr算法的重要指标； two 第一种是字符准确率，单字识别率，就是按单字算，一百个字里错5个字，识别率95%。
   > - 第二种是字段准确率，整行识别率，一个字段算一个整体，假如100个字分为20个字段，里面错了5个字，分布在4个字段里，那么识别率是16/20=80%。
   > - 第三种是整张准确率。通常在票据证件里面有这种计算方式，假设一张票据上有20字，4个字段，5张票上100个字，20字段，错了5个字，分布在4个字段里，分布在3张票据上。那么识别率只有2/5=40%。而且票据字段越多，容易出错的概率越高，整张识别率这个要求就越严苛。实测过程中也会有一些特别约定，说整张识别里错一两个字可以忽略的，这种再另说。
   >   同样是100字错5个，用字符、字段、整张准确率来测算的结果是完全不同的，所以对比不同OCR算法时候一定要看清描述的是单字识别率、整行识别率还是整张识别率。一样的识别率99%，整张识别率可比单字识别率的含金量要大得多。

2. latex文本

> AA: Alpha-Numeric Characters Prediction
> Accuracy, LTA: LaTeX Token Accuracy, LSA: LaTeX Symbol Accuracy, SA: Non-LaTeX Symbol Prediction Accuracy,
> EM: Exact Match Accuracy, EM@95%: Exact Match Accuracy @95% similarity. 

### 评价尺度

Character Confidence (scored between 0-100) determines the average accuracy of all character recognized in the table.
Usually, a type-written font comes with >95 score, while >80 on the handwritten ones are inferred good.

Layout Confidence (scored between 0-100) is the machine's heuristic in determining the layout of the table. Consider it
as to how good the characters alignment is recognized. Our observation shows

80-100: Perfect 70-80: Close to Perfect 60-70: Almost There - issues detecting the table ends. eg. Multi-column table
but only one "Total" column in the last row 50-60: Confused - usually on "middle aligned" multi-lined columns
<50: Human attention needed Note: Both confidence scores are calculated at the table level.

# loss

![](https://raw.githubusercontent.com/franztao/blog_picture/main/marktext/2022-05-25-12-01-18-image.png)

[从L1 loss到EIoU loss，目标检测边框回归的损失函数一览](https://zhuanlan.zhihu.com/p/342991797)

当前TableMaster用L1 loss出现：损失函数会在稳定值附近波动，难以收敛到更高精度。

# 相关技术分类

<img title="" src="https://raw.githubusercontent.com/franztao/blog_picture/main/2022-04-04-表格结构识别算法概览/method_overrall.png" alt="method overall" width="702">

## 表格识别各技术的进展情况

1. 基于启发式规则的方法

2. 基于CNN的方法

3. 基于GCN的方法

4. 基于End to End的方法

![img_11.png](https://raw.githubusercontent.com/franztao/blog_picture/main/2022-04-04-表格结构识别算法概览/img_11.png)
1）利用OCR检测文本，从文本框的空间排布信息推导出有哪些行、有哪些列、哪些单元格需合并，由此生成电子表格；
1）运用图像形态学变换、纹理提取、边缘检测等手段，提取表格线，再由表格线推导行、列、合并单元格的信息；
2，3）神经网络端到端学习，代表工作是TableBank，使用image to text技术，将表格图片转为某种结构化描述语言（比如html定义表格结构的标签）。
缺陷

>  思路1）极度依赖OCR检测结果和人工设计的规则，对于不同样式的表格，需做针对性开发，推广性差；
>     思路2）依赖传统图像处理算法，在鲁棒性方面较欠缺，并且对于没有可见线的表格，传统方法很吃力，很难把所有行/列间隙提取出来；
>     思路3）解决方案没有次第，一旦出现bad case，无法从中间步骤快速干预修复，只能重新调整模型（还不一定能调好），看似省事，实则不适合工程落地。

## 基于CNN的方法

Mask R-CNN architecture for table cell structure detection
![img.png](https://raw.githubusercontent.com/franztao/blog_picture/main/2022-04-04-表格结构识别算法概览/img20.png)
![ The architecture of Mask R-CNN (a) and Cascade Mask R-CNN (b). C, B and M denote class label, bounding box and mask predictions of the corresponding stage, respectively. Proposal head outputs are denoted with zero indexes.](https://raw.githubusercontent.com/franztao/blog_picture/main/2022-04-04-表格结构识别算法概览/img21.png)

![Hybrid Task Cascade architecture. S component represents the Semantic Segmentation Branch.](https://raw.githubusercontent.com/franztao/blog_picture/main/2022-04-04-表格结构识别算法概览/img22.png)

disadvantage： 1）数据漂移性  2） 识别的框会依次影响

## 基于GCN的方法

![img_14.png](https://raw.githubusercontent.com/franztao/blog_picture/main/2022-04-04-表格结构识别算法概览/img_14.png)
![img_15.png](https://raw.githubusercontent.com/franztao/blog_picture/main/2022-04-04-表格结构识别算法概览/img_15.png)

## 基于End to End的方法

![](https://raw.githubusercontent.com/franztao/blog_picture/main/marktext/2022-04-21-10-21-09-image.png)

![](https://raw.githubusercontent.com/franztao/blog_picture/main/marktext/2022-04-14-14-40-45-image.png)

![img_16.png](https://raw.githubusercontent.com/franztao/blog_picture/main/2022-04-04-表格结构识别算法概览/img_16.png)

### Table Grid Recognition

![img_19.png](https://raw.githubusercontent.com/franztao/blog_picture/main/2022-04-04-表格结构识别算法概览/img_19.png)

#### 内部原理

![](https://raw.githubusercontent.com/franztao/blog_picture/main/marktext/2022-04-14-14-44-50-image.png)

![](https://raw.githubusercontent.com/franztao/blog_picture/main/marktext/2022-04-21-11-16-49-image.png)

![](https://raw.githubusercontent.com/franztao/blog_picture/main/marktext/2022-04-21-11-16-58-image.png)

![](https://raw.githubusercontent.com/franztao/blog_picture/main/marktext/2022-04-14-14-37-46-image.png)

advantage: 1) 识别的框会聚焦 2）基于transformer的架构，可在上面做很多新的工作

disadvantage 1）缺少语义信息

## Table structure recognition

![img_18.png](https://raw.githubusercontent.com/franztao/blog_picture/main/2022-04-04-表格结构识别算法概览/img_18.png)![](https://raw.githubusercontent.com/franztao/blog_picture/main/marktext/2022-04-14-14-38-06-image.png)

![](https://raw.githubusercontent.com/franztao/blog_picture/main/marktext/2022-04-14-14-36-56-image.png)

效果呈现

![](https://raw.githubusercontent.com/franztao/blog_picture/main/marktext/2022-04-21-10-22-23-image.png)

海康方案

![](https://raw.githubusercontent.com/franztao/blog_picture/main/marktext/2022-04-21-10-24-33-image.png)

# 

A curated list of resources dedicated to table recognition ，借鉴（Awesome-Table-Recognition）

## 1. Papers

* *CODE means official code and CODE means not official code  

| *Conf.*           | *Date*    | *Title*                                                                                                                                                                                                                                                                               | *Highlight* | *code*                                                                                                                                               |
|:-----------------:|:---------:|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |:-----------:|:----------------------------------------------------------------------------------------------------------------------------------------------------:|
| CVPR              | 2022      | [TableFormer: Table Structure Understanding with Transformers.](https://arxiv.org/pdf/2203.01017.pdf)                                                                                                                                                                                 | Sequence    | No                                                                                                                                                   |
| CVPR              | 2022      | [Neural Collaborative Graph Machines for Table Structure Recognition](https://arxiv.org/pdf/2111.13359.pdf)                                                                                                                                                                           | GNN         | No                                                                                                                                                   |
| CVPR              | 2022      | [PubTables-1M: Towards comprehensive table extraction from unstructured documents](https://arxiv.org/pdf/2110.00061v3.pdf)                                                                                                                                                            | Dataset     | [*CODE](https://github.com/microsoft/table-transformer)<br>![](https://img.shields.io/github/stars/microsoft/table-transformer.svg?style=social)     |
| arXiv             | 2021/5/23 | [Multi-Type-TD-TSR -- Extracting Tables from Document Images using a Multi-stage Pipeline for Table Detection and Table Structure Recognition: from OCR to Structured Table Representations](https://arxiv.org/pdf/2105.11021.pdf)                                                    | Others      | [*CODE](https://github.com/Psarpei/Multi-Type-TD-TSR)<br>![](https://img.shields.io/github/stars/Psarpei/Multi-Type-TD-TSR.svg?style=social)         |
| ACM-MM            | 2021      | [Show, Read and Reason: Table Structure Recognition with Flexible Context Aggregator](https://dl.acm.org/doi/pdf/10.1145/3474085.3481534?casa_token=zwKnfTC97hwAAAAA:FnqKd6otw4v7LZQq_XvJzk_RLvit8ohPCOIafevI68zxXl1KocUVxIlBg9W1VsHQ57SShne6486BUw)                                  | GNN         | No                                                                                                                                                   |
| ICCV              | 2021      | [Parsing Table Structures in the Wild](https://openaccess.thecvf.com/content/ICCV2021/papers/Long_Parsing_Table_Structures_in_the_Wild_ICCV_2021_paper.pdf)                                                                                                                           | Dectction   | No                                                                                                                                                   |
| ICCV              | 2021      | [TGRNet: A Table Graph Reconstruction Network for Table Structure Recognition](https://openaccess.thecvf.com/content/ICCV2021/papers/Xue_TGRNet_A_Table_Graph_Reconstruction_Network_for_Table_Structure_Recognition_ICCV_2021_paper.pdf)                                             | GNN         | [*CODE](https://github.com/xuewenyuan/TGRNet)<br>![](https://img.shields.io/github/stars/xuewenyuan/TGRNet.svg?style=social)                         |
| ICDAR Competition | 2021      | [ICDAR 2021 Competition on Scientific Literature Parsing](https://arxiv.org/pdf/2106.14616v1.pdf)                                                                                                                                                                                     | Dataset     | [*CODE](https://github.com/ibm-aur-nlp/PubLayNet)<br>![](https://img.shields.io/github/stars/ibm-aur-nlp/PubLayNet.svg?style=social)                 |
| ICDAR Competition | 2021      | [PingAn-VCGroup's Solution for ICDAR 2021 Competition on Scientific Literature Parsing Task B: Table Recognition to HTML](https://arxiv.org/pdf/2105.01848v1.pdf)                                                                                                                     | Sequence    | [*CODE](https://github.com/JiaquanYe/TableMASTER-mmocr)<br>![](https://img.shields.io/github/stars/JiaquanYe/TableMASTER-mmocr.svg?style=social)     |
| ICDAR Competition | 2021      | [LGPMA: Complicated Table Structure Recognition with Local and Global Pyramid Mask Alignment](https://arxiv.org/pdf/2105.06224.pdf)                                                                                                                                                   | Others      | [*CODE](https://github.com/hikopensource/DAVAR-Lab-OCR)<br>![](https://img.shields.io/github/stars/hikopensource/DAVAR-Lab-OCR.svg?style=social)     |
| WACV              | 2021      | [Global table extractor (gte): A framework for joint table identification and cell structure recognition using visual context](https://openaccess.thecvf.com/content/WACV2021/papers/Zheng_Global_Table_Extractor_GTE_A_Framework_for_Joint_Table_Identification_WACV_2021_paper.pdf) | Others      | No                                                                                                                                                   |
| CVPR Workshop     | 2020      | [CascadeTabNet: An approach for end to end table detection and structure recognition from image-based documents](https://arxiv.org/pdf/2004.12629v2.pdf)                                                                                                                              | Others      | [*CODE](https://github.com/DevashishPrasad/CascadeTabNet)<br>![](https://img.shields.io/github/stars/DevashishPrasad/CascadeTabNet.svg?style=social) |
| ECCV              | 2020      | [Image-based table recognition: data, model, and evaluation](https://arxiv.org/pdf/1911.10683v5.pdf)                                                                                                                                                                                  | Dataset     | [*CODE](https://github.com/ibm-aur-nlp/PubTabNet)<br>![](https://img.shields.io/github/stars/ibm-aur-nlp/PubTabNet.svg?style=social)                 |
| ECCV              | 2020      | [Table structure recognition using top-down and bottom-up cues](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123730069.pdf)                                                                                                                                               | Others      | [*CODE](https://github.com/sachinraja13/TabStructNet)<br>![](https://img.shields.io/github/stars/sachinraja13/TabStructNet.svg?style=social)         |
| LREC              | 2020      | [TableBank: A Benchmark Dataset for Table Detection and Recognition](https://arxiv.org/abs/1903.01949)                                                                                                                                                                                | Dataset     | [*CODE](https://github.com/doc-analysis/TableBank)<br>![](https://img.shields.io/github/stars/doc-analysis/TableBank.svg?style=social)               |
| arXiv             | 2019/8/28 | [Complicated table structure recognition](https://arxiv.org/pdf/1908.04729.pdf)                                                                                                                                                                                                       | Others      | [*CODE](https://github.com/Academic-Hammer/SciTSR)<br>![](https://img.shields.io/github/stars/Academic-Hammer/SciTSR.svg?style=social)               |
| ICDAR             | 2019      | [Rethinking Table Recognition using Graph Neural Networks](https://arxiv.org/pdf/1905.13391v2.pdf)                                                                                                                                                                                    | GNN         | [*CODE](https://github.com/shahrukhqasim/TIES-2.0)<br>![](https://img.shields.io/github/stars/shahrukhqasim/TIES-2.0.svg?style=social)               |
| ICDAR             | 2019      | [Tablenet: Deep learning model for end-to-end table detection and tabular data extraction from scanned document images](https://arxiv.org/pdf/2001.01469.pdf)                                                                                                                         | Others      | No                                                                                                                                                   |
| ICDAR             | 2019      | [Res2tim: Reconstruct syntactic structures from table images.](https://ieeexplore.ieee.org/document/8978027)                                                                                                                                                                          | Others      | [*CODE](https://github.com/xuewenyuan/ReS2TIM)<br>![](https://img.shields.io/github/stars/xuewenyuan/ReS2TIM.svg?style=social)                       |
| ICDAR             | 2017      | [Deepdesrt: Deep learning for detection and structure recognition of tables in document images](https://www.dfki.de/fileadmin/user_upload/import/9672_PID4966073.pdf)                                                                                                                 | Others      | No                                                                                                                                                   |

# 数据集的汇总

![Table datasets. TD denotes table detection, TSR is table structure recognition whereas TR is table recognition.](https://raw.githubusercontent.com/franztao/blog_picture/main/2022-04-04-表格结构识别算法概览/table_datasets.png)

![](https://raw.githubusercontent.com/franztao/blog_picture/main/marktext/2022-04-06-18-57-32-image.png)

![](https://raw.githubusercontent.com/franztao/blog_picture/main/marktext/2022-04-12-16-11-24-image.png)

![](https://raw.githubusercontent.com/franztao/blog_picture/main/marktext/2022-05-18-11-45-36-image.png)

![](https://raw.githubusercontent.com/franztao/blog_picture/main/marktext/2022-05-18-12-19-42-image.png)

, 

| dataset                       | 规模    | 展示                                                                                                       | 与自有业务的GAP                  |
| ----------------------------- | ----- | -------------------------------------------------------------------------------------------------------- | -------------------------- |
| Wired Tables in theWild (WTW) | 14581 | ![](https://raw.githubusercontent.com/franztao/blog_picture/main/marktext/2022-08-16-19-24-19-image.png) | 拍照表格，多为田字形                 |
| pubtabnet                     | 568k  | ![](https://raw.githubusercontent.com/franztao/blog_picture/main/marktext/2022-08-16-19-33-05-image.png) | icdar2021,图片为缩略图           |
| Tablebank                     | 145k  | ![](https://raw.githubusercontent.com/franztao/blog_picture/main/marktext/2022-08-16-19-28-52-image.png) | pic为整张pdf图片,图片中有不止一张表格     |
| Pub-1M                        | 948K  | ![](https://raw.githubusercontent.com/franztao/blog_picture/main/marktext/2022-08-16-19-30-04-image.png) | pic为整张pdf图片,图片中有不止一张表格     |
| SynthTabNet_Fintabnet         | 150k  | ![](https://raw.githubusercontent.com/franztao/blog_picture/main/marktext/2022-08-16-19-34-58-image.png) |                            |
| SynthTabNet_marketing         | 150k  | ![](https://raw.githubusercontent.com/franztao/blog_picture/main/marktext/2022-08-16-19-35-30-image.png) | 格子多颜色背景                    |
| SynthTabNet_pubtabnet         | 150k  | ![](https://raw.githubusercontent.com/franztao/blog_picture/main/marktext/2022-08-16-19-35-50-image.png) | 仿真pubtabnet数据，表头多w文本跨行cell |
| SynthTabNet_sparse            | 150k  | ![](https://raw.githubusercontent.com/franztao/blog_picture/main/marktext/2022-08-16-19-36-19-image.png) | 图片为缩略图，多空白cell             |

## 竞赛

## ICDAR

| year | picture                                                                                                                                                                                                          | 备注                                                                                                                                           | size                                                                                                     | metric |
| ---- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------- | ------ |
| 2013 | ![](https://raw.githubusercontent.com/franztao/blog_picture/main/marktext/2022-08-18-10-36-40-image.png)                                                                                                         | 表格检测，表格格子识别                                                                                                                                  | 150                                                                                                      | IOU@AP |
| 2019 | ![](https://raw.githubusercontent.com/franztao/blog_picture/main/marktext/2022-08-18-10-27-48-image.png)![](https://raw.githubusercontent.com/franztao/blog_picture/main/marktext/2022-08-18-10-29-41-image.png) | The participating methods will be evaluated on a modern dataset and archival documents with printed and handwritten tables present. 表格格子关系预测 | ![](https://raw.githubusercontent.com/franztao/blog_picture/main/marktext/2022-08-18-10-26-50-image.png) | P，R，F1 |
| 2021 | ![](https://raw.githubusercontent.com/franztao/blog_picture/main/marktext/2022-08-16-19-33-05-image.png)                                                                                                         | 表格格子识别，表格结构识别                                                                                                                                | ![](https://raw.githubusercontent.com/franztao/blog_picture/main/marktext/2022-08-18-10-32-20-image.png) | TEDS   |

## 2. Datasets

### 2.1 Introduction

| Dataset       | Description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             | dataset link                                                                                  |
| ------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------- |
| TableBank     | **English** TableBank is a new image-based table detection and recognition dataset built with novel weak supervision from Word and Latex documents on the internet, contains 417K high-quality labeled tables.**It only contain cell Topology groudtruth**                                                                                                                                                                                                                                              | [TableBank](https://github.com/doc-analysis/TableBank)                                        |
| SciTSR        | ***English** SciTSR is a large-scale table structure recognition dataset, which contains 15,000 tables in PDF format and their corresponding structure labels obtained from LaTeX source files.**It contain cell Topology, cell content groudtruth**                                                                                                                                                                                                                                                    | [SciTSR](https://github.com/Academic-Hammer/SciTSR)                                           |
| PubTabNet     | **English** PubTabNet is a large dataset for image-based table recognition, containing 568k+ images of tabular data annotated with the corresponding HTML representation of the tables.**It contain cell Topology, cell content and non-blank cell location groudtruth**                                                                                                                                                                                                                                | [PubTabNet](https://github.com/ibm-aur-nlp/PubTabNet)                                         |
| FinTabNet     | **English** This dataset contains complex tables from the annual reports of S&P 500 companies with detailed table structure annotations to help train and test structure recognition.                                                                                                                                                                                                                                                                                                                   | [FinTabNet](https://developer.ibm.com/exchanges/data/all/fintabnet/)                          |
| PubTables-1M  | **English** A large, detailed, high-quality dataset for training and evaluating a wide variety of models for the tasks of table detection, table structure recognition, and functional analysis.                                                                                                                                                                                                                                                                                                        | [PubTables-1M](https://github.com/microsoft/table-transformer)                                |
| WTW           | **English and Chinese** WTW-Dataset is the first wild table dataset for table detection and table structure recongnition tasks, which is constructed from photoing, scanning and web pages, covers 7 challenging cases like: (1)Inclined tables, (2) Curved tables, (3) Occluded tables or blurredtables (4) Extreme aspect ratio tables (5) Overlaid tables, (6) Multi-color tables and (7) Irregular tables in table structure recognition.**It contain cell Topology, all cell location groudtruth** | [WTW](https://github.com/wangwen-whu/wtw-dataset)                                             |
| TNCR          | **English** a new table dataset with varying image quality collected from open access websites.TNCR contains 9428 labeled tables with approximately 6621 images.their classification into 5 different classes(Full Lined,Merged Cells,No lines,Partial Lined,Partial Lined Merged Cells).                                                                                                                                                                                                               | [TNCR](https://github.com/abdoelsayed2016/TNCR_Dataset)                                       |
| TAL_OCR_TABLE | **Chinese** TAL_OCR_TABLE dataset come from TAL Form Recognition Technology Challenge.The data of comes from the real homework of students in the education scene and the scene of the test paper. It contain 16k train image and 4k test image**It contain cell Topology, cell content and all cell location groudtruth**                                                                                                                                                                              | [TAL_OCR_TABLE](https://www.heywhale.com/home/competition/606d6fff0e04ac0017c3bf7f/content/1) |

### 2.2 Comparison of datasets for table structure recognition.

| Dataset       | Cell Topology | Cell content | Cell Location | Table Location |
| ------------- | ------------- | ------------ | ------------- | -------------- |
| TableBank     | ✓             | ✕            | ✕             | ✓              |
| SciTSR        | ✓             | ✓            | ✕             | ✓              |
| PubTabNet     | ✓             | ✓            | ✓<sup>†       | ✓              |
| FinTabNet     | ✓             | ✓            | ✓<sup>†       | ✓              |
| PubTables-1M  | ✓             | ✓            | ✓             | ✓              |
| WTW           | ✓             | ✕            | ✓             | ✓              |
| TNCR          | ✕             | ✕            | ✕             | ✓              |
| TAL_OCR_TABLE | ✓             | ✓            | ✓             | ✓              |

<sup>†</sup> For these datasets, cell bounding boxes are given for non-blank cells only and exclude any non-text portion of a cell.

## badcase数据集

![](C:\Users\franztao\AppData\Roaming\marktext\images\2022-09-14-19-49-18-image.png)

![](C:\Users\franztao\AppData\Roaming\marktext\images\2022-09-14-19-52-43-image.png)

![](C:\Users\franztao\AppData\Roaming\marktext\images\2022-09-14-19-52-51-image.png)

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/bRhTPYDIpHKicPNKHicQ4WnMGSP496rDgLZxQktBYJfDEnxw3uJCExqRLQBBB08rqldIXjIKYAZTtQZR70aruEaw/640?wx_fmt=jpeg&random=0.9801788830033764&wxfrom=5&wx_lazy=1&wx_co=1)

# 自研技术方案

## 当前效果展示

![](https://raw.githubusercontent.com/franztao/blog_picture/main/marktext/2022-04-14-14-40-45-image.png)

## 优化方向

1. 语义之间的信息
2. 节点里面的特征来引入
3. tsr grid recogniztion 无法将空白grid 识别出来

## 自研架构

![](https://raw.githubusercontent.com/franztao/blog_picture/main/marktext/2022-05-14-16-51-15-image.png)

![model_architecture.png](https://github.com/kingyiusuen/image-to-latex/blob/main/figures/model_architecture.png?raw=true)

# 研究分析若干问题

## 小目标检测问题

**1.小目标定义**

在不同场景下定义小目标的标准不尽相同，但现有的定义方式按学术上可主要分为两类：

**(1)基于相对尺度**

即从目标与图像的相对比例这一角度考虑来对小目标进行定义。Chen[1]等对小目标做了如下定义：同一类别中所有目标实例的相对面积，即边界框面积与图像面积之比的中位数在0.08%~0.58%之间。除此以外，较为常见的还有以下几种：①目标边界框的宽高与图像的宽高比例小于一定值，较为通用的比例值为0.1；②目标边界框面积与图像面积的比值开方小于一定值，较为通用的值为0.03；③根据目标实际覆盖像素与图像总像素之间比例来对小目标进行定义。

**(2)基于绝对尺度：**

即从目标绝对像素大小这一角度考虑来对小目标进行定义。目前最为通用的定义来自于目标检测领域的通用数据集——MS COCO数据集，将小目标定义为分辨率小于32像素×32像素的目标。除了MS COCO之外，还有其他基于绝对尺度的定义，如在航空图像数据集DOTA与人脸检测数据集WIDER FACE中都将像素值范围在[10，50]之间的目标定义为小目标。在行人识别数据集CityPersons中，将小目标定义为了高度小于75像素的目标。基于航空图像的小行人数据集TinyPerson则将小目标定义为像素值范围在［20，32］之间的目标。

**2.技术难点**

**(1)可利用特征较少**

小目标相比于大/中目标分辨率低，信息较少，难以提取到具有鉴别力的特征。

**(2)定位精度要求高**

小目标在图像中位置过小且极易受到环境干扰，网络预测时偏移一个像素则对小目标的影响是巨大的。

**(3)现有数据集中小目标占比少**

现有数据集较少关注小目标这一特别类型。同时，小目标不易标注，人力成本巨大，而且对误差更为敏感。

**(4)样本不均衡**

训练时通过设定阈值来判断锚框是否属于正样本，这样会导致不同尺寸目标的样本不均衡问题。因此，当人工设定的锚框与真实边框相差较大时，会导致模型忽略小目标的检测。

**(5)小目标聚集**

小目标更容易出现聚集的现象，这时网络模型的预测边框可能会因非极大值抑制过滤掉大量正确边框，导致漏掉小目标，或是边框距离过近，导致模型难以收敛。

**(6)网络结构**

目前现有算法针对小目标特性的优化设计不多，加之小目标自身特性所带来的难度，导致现有算法在小目标检测上普遍表现不佳。

**3.比较好的传统或深度学习方法**

**(1)多尺度学习**

多尺度是同时结合深层语义信息和浅层表征信息对小目标进行预测，是一种提升小目标检测性能的有效策略。

**(2)上下文学习**

上下文关系通常指场景中目标与场景或者目标与目标之间的约束和依赖关系，上下文学习即使学习这种关系，以此充分利用了图像中与目标相关的信息，能够有效提升小目标检测的性能[2]。基于上下文学习可分为两类：①隐式上下文特征，即指目标区域周围的背景特征或全局的场景特征。②显示上下文推理，指利用场景中明确的上下文信息来辅助推断目标的位置或类别。

**(3)无锚机制**

一种摆脱锚框机制的思路是将目标检测任务转换为关键点的估计，即基于关键点的目标检测方法，该方法主要包含两个大类：①基于角点的检测，通过对从卷积特征图中学习到的角点分组来预测目标边界框。②基于中心的检测[3]。预测出左上角和右下角的角点以及中心关键点，然后通过角点匹配确定边界框，最后利用预测的中心点消除角点不匹配引起的不正确的边界框。

**(4)优化损失函数**

在网络的训练过程中，小目标更容易受到随机误差的影响。[4]提出一种依据目标尺寸设定不同权重的损失函数。[5]将级联思想与焦距损失相结合，提出了Cascade RetinaNet。[6]提出了一种考虑前景背景之间平衡的损失函数，均有效提升了小目标的检测性能。

## IOU框各场景分析

利用两个 IoU 阈值，前景阈值 (Tf) 和背景阈值 (Tb)，我们可以定义以下错误类型（在 TIDE 论文的第 2.2 节中有更详细的解释）：

1. **分类错误 (CLS)**：IoU >= Tf 用于不正确类的目标（即，定位正确但分类错误）。

2. **定位误差 (LOC)**：Tb <= IoU < Tf 用于正确类别的目标（即，分类正确但定位不正确）。

3. Cls 和 Loc 错误 (CLS & LOC)：Tb <= IoU < Tf 用于不正确类的目标（即，分类和定位不正确）。

4. 重复检测错误 (DUP)：IoU >= Tf 表示正确类别的目标，但另一个得分较高的检测已经与目标匹配（即，如果不是得分较高的检测，那将是正确的）。

5. 背景误差 (BKG)：所有目标的 IoU < Tb（即，检测到的背景为前景）。

6. 丢失目标错误（MISS）：分类或定位错误尚未涵盖的所有未检测到的目标（假阴性）。

![图片](https://mmbiz.qpic.cn/mmbiz_png/7jnsg27ZEVGCqmjP617omhiabH29TAPcqmRK1CHpCCfILySw2SOLvCgUXFnMo13zKjqNGtR54gMCO8GxHBicrpPg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

# Resourse

## github

> https://github.com/shahrukhqasim/TIES-2.0
> Code for: S.R. Qasim, H. Mahmood, and F. Shafait, Rethinking Table Recognition using Graph Neural Networks (2019)
> TIES was my undergraduate thesis, Table Information Extraction System. I picked the name from there and made it 2.0 from there.
> 
> https://github.com/Irene323/GFTE
> A GCN-based table structure recognition method, which integrates position feature, text feature and image feature together.
> 
> https://github.com/jainammm/TableNet
> About Unofficial implementation of "TableNet: Deep Learning model for end-to-end Table detection and Tabular data extraction from Scanned Document Images"
> 
> https://github.com/eihli/image-table-ocr
> Turn images of tables into CSV data. Detect tables from images and run OCR on the cells.
> 
> https://github.com/HazyResearch/TreeStructure
> Fonduer has been successfully extended to perform information extraction from richly formatted data such as tables. A crucial step in this process is the construction of the hierarchical tree of context objects such as text blocks, figures, tables, etc. The system currently uses PDF to HTML conversion provided by Adobe Acrobat converter. Adobe Acrobat converter is not an open source tool and this can be very inconvenient for Fonduer users. We therefore need to build our own module as replacement to Adobe Acrobat. Several open source tools are available for pdf to html conversion but these tools do not preserve the cell structure in a table. Our goal in this project is to develop a tool that extracts text, figures and tables in a pdf document and maintains the structure of the document using a tree data structure.
> 
> https://github.com/mawanda-jun/TableTrainNet
> Table recognition inside douments using neural networks
> 
> https://github.com/doc-analysis/TableBank
> TableBank is a new image-based table detection and recognition dataset built with novel weak supervision from Word and Latex documents on the internet, contains 417K high-quality labeled tables.
> 
> https://github.com/cseas/ocr-table
> This project aims to extract tables from scanned image PDFs using Optical Character Recognition.
> 
> https://github.com/eihli/image-table-ocr
> Turn images of tables into CSV data. Detect tables from images and run OCR on the cells.
> 
> https://github.com/JiaquanYe/TableMASTER-mmocr
> 2nd solution of ICDAR 2021 Competition on Scientific Literature Parsing, Task B.

## 参考文献

Table Understanding Rethinking of the Problem.pdf，Alexey Shigarov
Current Status and Performance Analysis of
Table Recognition in Document Images
With Deep Neural Networks

https://zhuanlan.zhihu.com/p/379585300

## 3. Other technical solutions

### PRCV2021 Table Recognition Technology Challenge

- Competition First Place Solution  
  
  - [Solution Introduction](https://mp.weixin.qq.com/s?__biz=MzI1ODk1ODI5Mw%3D%3D&mid=2247489551&idx=1&sn=80bc256f88c51ae4c290debb9bc27148&chksm=ea016eb5dd76e7a3ab6be37fcc2b8d60b9dfbdbf46d7196cc27690eb6faf1ff5b9272732831f&mpshare=1&scene=1&srcid=0224YQwvvlj9xDO9aYeK2BvD&sharer_sharetime=1645665537919&sharer_shareid=72261baff3e3bd9cd5183f7dbcf5bf01#rd)  
  - [Solution Report PPT](https://mp.weixin.qq.com/s?__biz=MzI1ODk1ODI5Mw%3D%3D&mid=2247489551&idx=1&sn=80bc256f88c51ae4c290debb9bc27148&chksm=ea016eb5dd76e7a3ab6be37fcc2b8d60b9dfbdbf46d7196cc27690eb6faf1ff5b9272732831f&mpshare=1&scene=1&srcid=0224YQwvvlj9xDO9aYeK2BvD&sharer_sharetime=1645665537919&sharer_shareid=72261baff3e3bd9cd5183f7dbcf5bf01#rd)  

- Competition Second Place Method  
  
  - [Solution Report PPT](https://drive.google.com/file/d/1DM7vqrc2YGrLRd0RjTkQ7wrEJuoAknQo/view?usp=sharing)  

- Competition Third Place Method  
  
  - [Solution Report PPT](https://drive.google.com/file/d/1GSM6ms6EHVZQzgJS8rZ-27OblkaiUl8N/view?usp=sharing)  
    
    ### ICDAR 2021 Competition on Scientfic Literature Parsing TaskB: Table Recognition to HTML

- Competition First Place Solution  
  
  - [Solution Report PPT](https://davar-lab.github.io/files/icdar2021_lgpma/LGPMA-slides.pdf)  
  - [Solution Report Video](https://www.bilibili.com/video/BV19Q4y1Y73d?spm_id_from=333.999.0.0)  

- Competition Second Place Method  
  
  - [Solution Report PPT](https://github.com/JiaquanYe/TableMASTER-mmocr/blob/master/imgs/table2html.pdf)  
  - [Solution Report Video](https://www.bilibili.com/video/BV1pU4y1E7Fq?spm_id_from=333.999.0.0)
