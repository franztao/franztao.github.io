---
layout:     post
title:      多模态RAG调研，VRAG技术报告解读
subtitle:   2025年7月
date:       2025-07-18
author:     franztao
header-img: post-bg-re-vs-ng2.jpg
catalog: true
tags:
    - RAG
    - RL
    - 多模态

---

# 为什么提出VRAG

思路：传统的的文本RAG,一些场景解决不了，具体哪些场景解决不了，然后提出VRAG

1)视觉信息处理能力不足：基于文本的 RAG 方法无法有效解析图像中的信息，缺乏对视觉数据的理解和推理能力。

2）固定流程限制动态推理：现有视觉 RAG 方法多采用固定的检索-生成流程，难以在复杂任务中动态调整推理路径，限制了模型挖掘视觉信息的能力。

3）检索效率与推理深度不足：传统方法在处理复杂视觉任务时，往往无法高效定位关键信息，导致生成结果不够精准。

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/2M9qP5jvk8QXmO01/img/09cc276b-e147-491f-9560-72060d219d4a.png)

## 检索增强生成（RAG）技术演进

检索增强生成技术经历了从纯文本到多模态的发展历程

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/a/RxENobqebh029A3b/d51a7a01d4914b7b82bce372661b782a3740.png)

## 当前视觉RAG方法的系统性局限

现有视觉RAG方法可分为三类，每类都存在根本性局限：

| **方法类型** | **代表方法** | **核心思路** | **主要问题** |
| --- | --- | --- | --- |
| **嵌入式方法** | CLIP-RAG | 将图像编码为固定嵌入向量 | 信息压缩损失，无法处理细节 |
| **描述式方法** | Caption-RAG | 先生成图像描述再检索 | 视觉信息丢失，描述不准确 |
| **端到端方法** | VisualBERT-RAG | 直接处理图文混合输入 | 缺乏动态交互，推理能力有限 |

# 做什么，解决什么难点

思路：由这些场景，抽象出哪些难点挑战

## 挑战1：视觉信息的层次性处理需求

视觉信息具有天然的层次结构，需要不同粒度的处理策略：

```plaintext
视觉信息层次结构：
├── 全局语义层（整体场景理解）
│   ├── 场景类型识别
│   └── 主体对象定位
├── 局部区域层（重点区域分析）
│   ├── 关键区域识别
│   └── 区域间关系建模
├── 细节元素层（精确信息提取）
│   ├── 文字OCR识别
│   ├── 数值数据提取
│   └── 符号标记理解
└── 空间关系层（位置和布局）
    ├── 相对位置关系
    └── 逻辑结构分析
```

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/2M9qP5jvk8QXmO01/img/f6a47e30-50f8-411d-9237-ee0aa4942079.png)

**举例图**

## 挑战2：检索策略的适应性需求

传统RAG采用**静态检索模式**，即"一次检索，直接生成"，这种模式在复杂视觉推理任务中显然不足：

```markdown
# 传统静态RAG流程
def static_rag(query, knowledge_base):
    # 单次检索
    retrieved_docs = retrieve_once(query, knowledge_base)
    # 直接生成
    answer = generate_answer(query, retrieved_docs)
    return answer
```

## 由挑战1和2引出挑战3：奖励信号设计的复杂性

视觉RAG任务的性能评估需要考虑多个维度，单一的结果奖励无法有效指导训练：

```markdown
检索相关性：检索到的文档是否与查询相关
视觉理解准确性：对图像内容的理解是否正确
推理逻辑性：推理过程是否符合逻辑
答案完整性：最终答案是否完整准确
效率性：达成目标所需的步骤数
```

**RL+tool,基于GRPO算法，在工具上提出了很多改进方案，改进了很多方法**

# 怎么做

*   思路：基于做什么，提出各种技术解决和优化
    

## 挑战1：视觉信息的层次性处理需求

### 视觉感知动作空间设计

VRAG-RL的视觉感知动作空间基于**人类视觉注意力机制**的计算建模。人类在处理复杂视觉信息时，会通过**选择性注意**机制聚焦于重要区域，这一过程可以建模为序列决策问题。

```markdown
class TemporalAttentionModule:
    def __init__(self, hidden_dim=512):
        self.temporal_encoder = nn.LSTM(hidden_dim, hidden_dim, batch_first=True)
        self.attention_layer = nn.MultiheadAttention(hidden_dim, num_heads=8)

    def forward(self, video_features, query_embedding):
        """时序注意力计算"""
        # 时序编码
        temporal_features, _ = self.temporal_encoder(video_features)

        # 查询引导的时序注意力
        query_expanded = query_embedding.unsqueeze(0).repeat(
            temporal_features.size(1), 1, 1
        )

        attended_features, attention_weights = self.attention_layer(
            query=query_expanded,
            key=temporal_features.transpose(0, 1),
            value=temporal_features.transpose(0, 1)
        )

        return attended_features.transpose(0, 1), attention_weights
```

### 动作空间的数学定义

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/2M9qP5jvk8QXmO01/img/dd80d4ca-c63e-4bcd-8a3d-80cf363038c8.png)

```markdown
class VisualActionSpace:
    def __init__(self, image_size=(224, 224)):
        self.image_size = image_size
        self.action_types = [
            'region_select', 'zoom_in', 'zoom_out',
            'crop_extract', 'scan_horizontal', 'scan_vertical',
            'focus_text', 'focus_diagram', 'global_view'
        ]

    def select_region(self, image, coordinates, attention_weights=None):
        """基于坐标和注意力权重选择感兴趣区域"""
        x1, y1, x2, y2 = coordinates

        # 确保坐标在有效范围内
        x1 = max(0, min(x1, image.width))
        y1 = max(0, min(y1, image.height))
        x2 = max(x1, min(x2, image.width))
        y2 = max(y1, min(y2, image.height))

        # 提取区域
        region = image.crop((x1, y1, x2, y2))

        # 如果提供了注意力权重，进行加权处理
        if attention_weights is not None:
            region = self.apply_attention_weighting(region, attention_weights)

        return self.encode_region(region)

```

### 渐进式视觉感知策略

VRAG-RL采用**从粗到细**的渐进式感知策略，模拟人类视觉系统的工作模式

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/a/RxENobqebh029A3b/24e18066acb146a091a009f61b83720c3740.png)

```markdown
class ProgressiveVisualPerception:
    def __init__(self):
        self.global_analyzer = GlobalLayoutAnalyzer()
        self.region_detector = SalientRegionDetector()
        self.detail_extractor = DetailExtractor()
        self.multi_scale_fusion = MultiScaleFusion()

    def perceive(self, image, query, max_steps=5):
        perception_history = []
        current_focus = "global"

        for step in range(max_steps):
            if current_focus == "global":
                # 全局分析阶段
                global_features = self.global_analyzer(image)
                salient_regions = self.region_detector(image, global_features)

                perception_history.append({
                    'step': step,
                    'type': 'global',
                    'features': global_features,
                    'regions': salient_regions
                })

                # 决定下一步焦点
                current_focus = self.decide_next_focus(salient_regions, query)

            elif current_focus == "regional":
                # 区域分析阶段
                selected_regions = self.select_top_regions(salient_regions, query)
                regional_features = []

                for region in selected_regions:
                    region_crop = self.crop_region(image, region.bbox)
                    features = self.detail_extractor(region_crop)
                    regional_features.append(features)

                perception_history.append({
                    'step': step,
                    'type': 'regional',
                    'features': regional_features,
                    'regions': selected_regions
                })

                current_focus = "detail"

            elif current_focus == "detail":
                # 细节提取阶段
                detailed_info = self.extract_fine_details(
                    image, selected_regions, query
                )

                perception_history.append({
                    'step': step,
                    'type': 'detail',
                    'info': detailed_info
                })

                # 判断是否需要继续
                if self.termination_condition(detailed_info, query):
                    break
                else:
                    current_focus = "global"  # 可能需要重新全局分析

        # 多尺度信息融合
        fused_representation = self.multi_scale_fusion(perception_history)
        return fused_representation
```

## 挑战2：检索策略的适应性需求

就比如当前这个ppt,我看不清楚是不是会放大再看清楚

```markdown
# VRAG-RL动态RAG流程
def dynamic_rag(query, visual_content, knowledge_base):
    state = initialize_state(query, visual_content)
    context_history = []

    for step in range(max_reasoning_steps):
        # 基于当前状态选择动作
        action = policy_network.select_action(state)

        # 执行视觉感知动作
        if action.type == "visual_focus":
            focused_region = focus_on_region(visual_content, action.coordinates)
            state.update_visual_context(focused_region)
        elif action.type == "retrieve":
            new_docs = adaptive_retrieve(state.current_query, knowledge_base)
            state.update_retrieved_docs(new_docs)
        elif action.type == "reason":
            partial_result = reasoning_step(state)
            context_history.append(partial_result)

        # 判断是否达到终止条件
        if termination_condition(state, context_history):
            break

    return generate_final_answer(context_history)
```

## 由挑战1和2引出挑战3：奖励信号设计的复杂性

### 奖励函数的理论设计

VRAG-RL的奖励函数设计基于**多目标优化理论**，需要平衡不同维度的性能指标：

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/2M9qP5jvk8QXmO01/img/be18fb43-826c-45bf-a9f9-6b3ebf7ce3d3.png)

### 检索效率奖励设计![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/2M9qP5jvk8QXmO01/img/7230a3df-b111-4fca-9426-4f49da18a40a.png)

检索效率奖励基于**信息检索理论**中的相关性评估指标，但针对视觉内容进行了扩展：

**传统NDCG计算**：

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/2M9qP5jvk8QXmO01/img/68b70f5d-351a-4f14-8b49-881fb1908c06.png)

**视觉增强NDCG计算**：

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/2M9qP5jvk8QXmO01/img/ed70b8e8-5a5c-4c37-a02a-edddb1081dcc.png)

```markdown
class RetrievalRewardCalculator:
    def __init__(self):
        self.visual_relevance_model = VisualRelevanceModel()
        self.text_relevance_model = TextRelevanceModel()

    def compute_retrieval_reward(self, query, retrieved_docs, visual_context=None):
        """计算检索效率奖励"""
        relevance_scores = []

        for doc in retrieved_docs:
            # 文本相关性
            text_rel = self.text_relevance_model.score(query, doc.text)

            # 视觉相关性（如果有视觉上下文）
            visual_rel = 1.0  # 默认值
            if visual_context is not None and doc.has_visual:
                visual_rel = self.visual_relevance_model.score(
                    visual_context, doc.visual_content
                )

            # 综合相关性
            combined_rel = 0.6 * text_rel + 0.4 * visual_rel
            relevance_scores.append(combined_rel)

        # 计算NDCG
        dcg = self.compute_dcg(relevance_scores)
        ideal_dcg = self.compute_ideal_dcg(relevance_scores)

        ndcg = dcg / ideal_dcg if ideal_dcg > 0 else 0
        return ndcg

    def compute_dcg(self, relevance_scores):
        """计算折扣累积增益"""
        dcg = 0
        for i, score in enumerate(relevance_scores):
            dcg += (2**score - 1) / math.log2(i + 2)
        return dcg
```

### 模式一致性奖励设计![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/2M9qP5jvk8QXmO01/img/be737046-3503-4dfe-855c-a4bb2c5fe2d6.png)

模式一致性奖励确保模型遵循合理的推理模式，避免无效的随机探索：

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/2M9qP5jvk8QXmO01/img/ec2c298b-4547-474a-b0e4-a77b76c3c18b.png)

```markdown
class ReasoningPattern:
    def __init__(self):
        self.valid_transitions = {
            'start': ['global_view', 'region_select'],
            'global_view': ['region_select', 'retrieve'],
            'region_select': ['detail_extract', 'zoom_in', 'crop'],
            'detail_extract': ['retrieve', 'reason'],
            'retrieve': ['reason', 'region_select'],
            'reason': ['retrieve', 'region_select', 'answer'],
            'answer': ['end']
        }

    def is_valid_transition(self, current_state, action, next_state):
        """检查状态转移是否符合推理模式"""
        return next_state in self.valid_transitions.get(current_state, [])

    def compute_pattern_reward(self, transition_history):
        """计算模式一致性奖励"""
        valid_transitions = 0
        total_transitions = len(transition_history) - 1

        for i in range(total_transitions):
            current = transition_history[i]['state']
            action = transition_history[i]['action']
            next_state = transition_history[i+1]['state']

            if self.is_valid_transition(current, action, next_state):
                valid_transitions += 1

        pattern_consistency = valid_transitions / total_transitions if total_transitions > 0 else 1.0

        # 奖励函数设计
        if pattern_consistency >= 0.8:
            return 1.0
        elif pattern_consistency >= 0.6:
            return 0.5
        elif pattern_consistency >= 0.4:
            return 0.0
        else:
            return -0.5
```

### 答案质量奖励设计![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/2M9qP5jvk8QXmO01/img/d4e34400-337d-40e2-885d-258894f8a10e.png)

答案质量奖励采用**多维度评估**方法，结合自动化指标和模型(有一个RM模型)评估：

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/2M9qP5jvk8QXmO01/img/a305f720-1e32-4df8-940f-ab58e6c12da2.png)

```markdown
class AnswerQualityEvaluator:
    def __init__(self):
        self.semantic_evaluator = SemanticSimilarityModel()
        self.factual_checker = FactualAccuracyChecker()
        self.completeness_analyzer = CompletenessAnalyzer()
        self.reference_model = ReferenceModel()

    def compute_answer_reward(self, generated_answer, reference_answer, context=None):
        """计算答案质量奖励"""

        # 1. 语义相似度评估
        semantic_score = self.semantic_evaluator.compute_similarity(
            generated_answer, reference_answer
        )

        # 2. 事实准确性检查
        factual_score = self.factual_checker.verify_facts(
            generated_answer, reference_answer, context
        )

        # 3. 完整性评估
        completeness_score = self.completeness_analyzer.assess_completeness(
            generated_answer, reference_answer
        )

        # 4. 参考模型评分
        reference_score = self.reference_model.score(
            generated_answer, reference_answer
        )

        # 加权组合
        final_score = (
            0.3 * semantic_score +
            0.3 * factual_score +
            0.2 * completeness_score +
            0.2 * reference_score
        )

        return final_score
```

# 实验设计与性能分析

#### 实验数据集详细介绍

VRAG-RL在多个具有挑战性的视觉密集型数据集上进行了全面评估：

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/2M9qP5jvk8QXmO01/img/ba9593d0-2d7a-4872-ad1f-548089526e99.png)

| **数据集** | **任务类型** | **数据特点** | **样本数量** | **评估指标** | **挑战特点** |
| --- | --- | --- | --- | --- | --- |
| **SlideVQA** | 幻灯片问答 | 学术演示文档，复杂布局 | 2,568 | Accuracy, F1, BLEU | 多层次信息整合 |
| **ViDoSeek** | 视频内容检索 | 动态视觉内容理解 | 1,234 | Recall@K, MRR, MAP | 时序信息处理 |
| **ChartQA** | 图表数据分析 | 科学图表，数值推理 | 3,456 | Exact Match, Numerical Accuracy | 精确数值理解 |
| **DocVQA** | 文档理解 | 多页文档，复杂排版 | 5,678 | ANLS, Relaxed Accuracy | 长文档处理 |
| **TextVQA** | 场景文字理解 | 自然场景中的文字识别 | 4,321 | Accuracy, CIDEr | OCR与理解结合 |

#### 性能提升深度分析

##### 核心指标对比

```plaintext
VRAG-RL vs. 基线方法性能对比：

整体性能提升：
├── Qwen2.5-VL-7B基础: 34.7 → 57.1 (+64.8%)
├── GPT-4V基线对比: 提升15.3个百分点
└── 最强视觉RAG基线: 提升23.7个百分点

分任务性能分析：
├── 图表理解任务: +28.5% (ChartQA数据集)
├── 文档问答任务: +22.1% (DocVQA数据集)  
├── 幻灯片分析: +31.2% (SlideVQA数据集)
├── 视频检索任务: +18.9% (ViDoSeek数据集)
└── 场景文字理解: +25.4% (TextVQA数据集)

效率提升指标：
├── 平均推理步数: 8.2 → 5.7 (-30.5%)
├── 检索精度Recall@1: +20.3%
├── 首次命中率: +27.8%
└── 端到端延迟: -15.2%
```

# 应用场景

1.  **教育辅助系统**  
    生物学课堂中，学生提问“细胞有丝分裂过程”，系统定位教材插图中分裂各期阶段，放大展示纺锤体结构，生成动态解说动画。
    
2.  **金融图表分析**  
    自动识别财报中的股价K线图，聚焦关键波动节点，结合新闻事件生成归因报告。在回测中准确捕捉**87%** 的趋势转折信号。
    
3.  **多模态客服引擎**  
    用户上传家电故障图，系统先定位错误代码区域，二次放大电路板烧蚀点，关联维修知识库生成解决方案。
    

# 总结

**核心技术创新总结**

**实验验证成果**

**学术价值与实践意义**

**未来发展前景**

# 参考资料

[https://mp.weixin.qq.com/s/Q0Q29PapcGlfZKP2ClRlSA: https://mp.weixin.qq.com/s/Q0Q29PapcGlfZKP2ClRlSA](https://mp.weixin.qq.com/s/Q0Q29PapcGlfZKP2ClRlSA)

[https://mp.weixin.qq.com/s/6zuo7ltNrO8VUM006LI-lg: https://mp.weixin.qq.com/s/6zuo7ltNrO8VUM006LI-lg](https://mp.weixin.qq.com/s/6zuo7ltNrO8VUM006LI-lg)

[https://mp.weixin.qq.com/s/PVNHO1Fg0oTe8UAj5ST7Vg: https://mp.weixin.qq.com/s/PVNHO1Fg0oTe8UAj5ST7Vg](https://mp.weixin.qq.com/s/PVNHO1Fg0oTe8UAj5ST7Vg)