---
layout:     post
title:      文档智能技术路线
subtitle:   2025年5月
date:       2025-05-23
author:     franztao
header-img: post-bg-re-vs-ng2.jpg
catalog: true
tags:
    - multimodel
    - LLM
    - 文档智能
    - VLM
    - VLLM

---



# 文档智能技术路线``

## 文档智能技术pipeline和end2end的区别

|  **技术类型**  |  **Pipeline（OCR-nofree）**  |  **End2End（OCR-free）**  |
| --- | --- | --- |
|  **代表工作**  |  PP-Structure、RagFlow、Miner-U、PPOCR v5.0  |  **通用 VLM**：GPT-4V、Claude、Gemini **专用模型**：Dolphine、Donut、Nougat、KOSMOS-2.5、Monkey、Vary  |
|  **优点**  |  1. 模块化优化，灵活性强 2. 鲁棒性高（适应复杂版式） 3. 技术复用成本低  |  1. 端到端流程极简 2. 多任务兼容（Prompt 驱动） 3. 扩展性高（快速适配新场景） 4. 弱数据依赖（部分零样本）  |
|  **缺点**  |  1. 流程复杂，维护成本高 2. 错误传播风险 3. 后处理逻辑复杂（布局检测、顺序还原） 4. 方案同质化  |  1. 数据瓶颈（语种偏向、噪声） 2. 模型缺陷（幻觉、延迟高） 3. 技术同质化（ViT+LLM 复用） 4. 可控性弱  |

### Pipeline（ocr-nofree） 技术总结

#### 基本原理

文档智能 Pipeline 是一种分阶段处理文档结构化的技术方案，核心流程为：

1.  **文档转图片**：将输入文档（如 PDF、扫描件）转换为图像格式。
    
2.  **版式布局分析**：通过目标检测模型分割出文档中的图、表、公式、段落等元素区域。
    
3.  **分模块解析**：对检测出的不同区域分别处理（表格解析、公式识别、段落 OCR 等）。
    
4.  **后处理与整合**：对解析结果进行阅读顺序还原、格式修复、结构化输出（如 Markdown）。
    

#### 代表工作

*   **PP-Structure**（PaddlePaddle）：首个系统化实现该流程的开源工具，支持多元素解析。
    
*   **RagFlow**：结合检索增强生成（RAG）的文档处理工具，增强语义理解能力。
    
*   **Miner-U**：面向工业场景优化的文档解析方案，强调后处理逻辑的完善性。
    
*   **PPOCR v5.0**：升级版 OCR 模型，提升段落文本识别精度。
    

#### 优点

1.  **模块化优化**：各组件可独立优化（如表格解析用最佳模型，OCR 用最新算法），灵活性强。
    
2.  **强鲁棒性**：分阶段处理对复杂版式（如多栏、混合图文）适应性较好。
    
3.  **技术复用**：可集成开源成熟模块（如 PyMuPDF 转图片、LaTeX 公式识别），降低开发成本。
    

#### 缺点

1.  **流程复杂性**：多阶段串联导致系统臃肿，部署和维护成本高。
    
2.  **错误传播**：前置步骤的误差（如漏检公式）会累积影响最终结果，全局纠错困难。
    
3.  **后处理挑战**：
    
    *   布局检测不全（如重叠区域漏检）；
        
    *   扫描版与可编辑版内容差异大，OCR 结果需针对性适配；
        
    *   阅读顺序还原依赖启发式规则，对非标准版式易出错。
    
4.  **方案同质化**：现有工具流程趋同，差异仅在于模块选型与后处理细节优化。
    

###  End2End（ocr-free）  技术总结

#### 基本原理

通过 **多模态大模型** 直接实现“图片+指令→结构化文本”的端到端解析，无需传统 OCR 或分模块处理流程。核心技术包含：

1.  **模型架构**：视觉编码器（如 ViT、SwinTransformer）提取图像特征 → 跨模态对齐模块（如交叉注意力） → 文本解码器（如 GPT、T5）生成结构化输出（如 Markdown）。
    
2.  **数据驱动**：需构建 `<prompt, 文档图片, OCR结果>` 三元组数据集，通过微调（如 LoRA）对齐图文特征。
    
3.  **特性优化**：针对文档高分辨率、密集文本的特点，优化视觉词表（如 Vary）、动态采样（如 Monkey）或引入元数据（如 OLM-OCR）。
    

---

#### 代表工作

**两大技术流派**：

1.  **通用多模态大模型（VLM）**：
    
    *   **代表模型**：GPT-4V、Claude、Gemini、Qwen-VL、InternVL
        
    *   **特点**：支持开放域任务，依赖模型通用能力，需通过 Prompt 工程适配文档解析需求。
    
2.  **专用文档解析模型**：
    
    *   **代表模型**：
        
        *   _经典架构_：Donut（ViT+MBART）、Nougat（Swin+Transformer）、KOSMOS-2.5（ViT+LLM）
            
        *   _创新设计_：Monkey（动态分辨率）、Vary（扩展视觉词表）、OLM-OCR（元数据增强）
        
    *   **特点**：针对文档场景定制，优化视觉编码器与跨模态对齐能力。
        

---

#### 优点

1.  **流程极简**：端到端处理，省去传统 OCR 的复杂流水线（如布局分析、分模块解析），降低错误传播风险。
    
2.  **多任务兼容**：通过 Prompt 灵活支持表格转 Markdown、公式识别、阅读顺序还原等任务。
    
3.  **高扩展性**：基于预训练大模型，可通过微调快速适配新文档类型或语言（如古文、多栏排版）。
    
4.  **弱依赖数据**：部分模型（如 GPT-4V）无需标注数据，直接零样本推理。
    

---

#### 缺点

1.  **数据瓶颈**：
    
    *   依赖海量高质量 `<图片, OCR结果>` 对齐数据，但现有数据集（如 arXiv 论文）存在语种偏向（英文为主）和噪声（PDF 渲染缺陷）。
        
    *   中文、小语种文档支持不足，长尾场景（如手写体、复杂表格）性能差。
    
2.  **模型缺陷**：
    
    *   **幻觉问题**：易生成与图片无关的虚构内容（如错误公式、乱序文本）。
        
    *   **计算成本高**：大模型推理延迟显著（如 GPT-4V），需依赖 GPU 加速（如 vLLM），难以实时部署。
    
3.  **技术同质化**：多数模型复用相似架构（ViT+LLM），创新集中在数据增强或局部优化（如分辨率、词表）。
    
4.  **可控性弱**：输出格式依赖 Prompt 设计，复杂文档（如多页 PDF）需多次交互修正。
    

# Miner-U架构

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/Yvenve5PR4am1loy/img/916e59ff-3c1d-4625-b207-e6094d21241a.png)

# 参考内容

[https://github.com/SpursGoZmy/Tabular-LLM](https://github.com/SpursGoZmy/Tabular-LLM)

[https://mp.weixin.qq.com/s/jTxH5JiJtz6f88z503CtaQ](https://mp.weixin.qq.com/s/jTxH5JiJtz6f88z503CtaQ)

[https://aicarrier.feishu.cn/file/SknGbA2nqoYodbxNjYRcqeUsngf](https://aicarrier.feishu.cn/file/SknGbA2nqoYodbxNjYRcqeUsngf)

[https://paddlepaddle.github.io/PaddleOCR/main/version3.x/algorithm/PP-OCRv5/PP-OCRv5.html](https://paddlepaddle.github.io/PaddleOCR/main/version3.x/algorithm/PP-OCRv5/PP-OCRv5.html)

[https://github.com/bytedance/Dolphin?tab=readme-ov-file](https://github.com/bytedance/Dolphin?tab=readme-ov-file)

[https://paddlepaddle.github.io/PaddleOCR/main/](https://paddlepaddle.github.io/PaddleOCR/main/)
